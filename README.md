# AI For Enegy Access (AI4EA)
### Reiner Lemoine Instut and Atlas AI for Lacuna Fund

This repository presents the context, code, and results of the Machine Learning (ML) approach to AI For Energy Access (AI4EA) inference component of the initiative.


## Objective

We will use the PeopleSun georeferenced survey responses (restricted access) that contains a reported census of appliances. The applicance counts are a predictor of electricity consumption. The appliance counts will be used to train a machine learning (ML) model to predict, i.e. infer, the estimated appliance types and number for out of sample areas.

Since the survey data were collected in specific zones in Nigeria, "out of sample" in this case implies other inhabited, settled communities in Nigeria and beyond.

In line with the broader goal of the project we will use the model to estimate appliance types and counts in four other countries.


## Summary Exploratory Data Analysis

While many different EDA were performed, some main insights are synthesized:
- the distributions of the number of appliances owned by HH are all right-skewed, i.e. most of the probability weight is in the lower end of the distribution
- for appliances such as laptops, radios, and televisions in particular it might be appropriate to treat the data as categorical, because most HHs either have none or one of each of these. 
- outliers may need to be handled through winsorization. for example, some HHs are reported to have 40 phone chargers, which needs to be handled in label pre-processing


![A count of appliances](figures/appliancesHH.png)


## Webmap

The webmap is provided as a tool to visualize and compare the load profiles generated interactively. 

### Local setup

After setting up a virtual environment, install the requirements with 
`pip install -r webmap/requirements.txt`

Some data is required by the webapp. It is already provided for your convenience, however you might want to generate your own data, we explain thereafter how to proceed then. The required data encompasses:

1. A set of indicators to be displayed for each administrative level 2 region to be provided within `webmap/static/data/webmap_layers.geojson`, see below how to generate your own file from the machine learning outputs files.
2. The daily load profiles averaged form the full year minute resolution load profiles need to be provided for each country with the following convention: `webmap/static/data/{country ISO3}_timeseries_daily_avg.nc` (you need to replace `{country ISO3}` by your country ISO3, like "NGA" or "NER"). See below how to generate your own files from the RAMP simulation output.


#### How to produce `webmap_layers.geojson` file
You can generate the file yourself by downloading  `*_stats.geojson` from the Harvard dataverse, save it temporarily in `script/` folder and run the `scripts/generate_webmap_layers.py`. Then save the webmap_layers.geojson in `webmap/static/data`. The files `*_stats.geojson` contains some indicators of the load profile: minimum (min), maximum (max), aggregated (sum), and average (mean) are calculated from the yearly minute resolution load profiles for each administrative level 2 (adm2 and adm1 properties). If the adm1 property is set to "dummy", it means that the adm2 property set identifies the regions uniquely. The indicators are also provided per household (same label with "hh_" as prefix, i.e "hh_max") to ease the comparison between regions. The household number (num_hh) and a cluster attribution (from 1 to 3) where generated from the ML model and are available as properties as well. They can also be generated from the Machine Learning outputs and the load profiles generated by RAMP within the notebook `DemandProfiles/analysis_template_daily_profiles.ipynb` under the section 'Exporting data for further use in a webmap'.

#### How to produce `{country_iso}_timeseries_daily_avg.nc` files

Those files contains the statistical daily load profile in  `.nc` format, used to display the load profile curves in the webmap. Those files are generated from the `{country_iso}_all_intermediate_avg_*.csv` files from Harvard dataverse using the The `scripts/daily_profiles_csv_to_nc.py` script. To do so, temporarily save the  `{country_iso}_all_intermediate_avg_*.csv` files, downloaded from Harvard dataverse or that you generated with `DemandProfiles/generate_demand_profiles.py`, in the `script/` folder. You can create one folder per country or have all countries within one folder but make sure that you set the `country_iso = " "` in the `scripts/daily_profiles_csv_to_nc.py` to the target country before running it. There is also a description of the same conversion process within the `DemandProfiles/analysis_template_daily_profiles.ipynb` file under the "Exporting data for further use in a webmap" section.

Run the app using `uvicorn webmap.main:app --host 0.0.0.0 --port 8000 --reload` in the root of this repository, it will then be available under `http://127.0.0.1:8000/` in your browser.

### Deploy

The current state of the `webmap` folder is already prepared to deploy the app on Caprover, the `captain-definition` file at the root of the repository links to the Dockerfile.  

You need to add a `webmap/.env` file in which you need to provide
```
ENV=prod
TRUSTED_HOST=<https://yourdomain.com>
``` 